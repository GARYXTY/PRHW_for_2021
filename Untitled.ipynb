{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import optuna.integration.lightgbm as olgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('Train.csv')\n",
    "test_data = pd.read_csv('Test.csv')\n",
    "label = train_data['y']\n",
    "num_feature = ['age', 'duration', 'campaign', 'pdays', 'previous', 'emp.var.rate', 'cons.price.idx',\n",
    "       'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "cate_feature = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact'\n",
    "               ,'month', 'day_of_week', 'poutcome']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_data[num_feature].min()\n",
    "b = train_data[num_feature].max()\n",
    "\n",
    "def dataset_transform(dataset):\n",
    "    data_after = (dataset[num_feature]-a)/(b-a) \n",
    "    for name in cate_feature:\n",
    "        data_after = pd.concat([data_after, pd.get_dummies(dataset[name], prefix=name)], axis =1)\n",
    "    c = itertools.combinations(cate_feature,2)\n",
    "    for i in c:\n",
    "        name1 = i[0]\n",
    "        name2 = i[1]\n",
    "        data_after = pd.concat([data_after,feature_generation(name1, name2, dataset)], axis=1)\n",
    "    return data_after\n",
    "\n",
    "train_data_1 = dataset_transform(train_data)\n",
    "test_data_1 = dataset_transform(test_data)\n",
    "labels = pd.get_dummies(label)\n",
    "labels = labels['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_generation(name1, name2, dataset):\n",
    "    test1 = pd.get_dummies(dataset[name1], prefix=name1)\n",
    "    test2 = pd.get_dummies(dataset[name2], prefix=name2)\n",
    "    K = pd.DataFrame()\n",
    "    for i in test1.columns:\n",
    "        for j in test2.columns:\n",
    "            K[i+j] = test1[i]*test2[j]\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "10573    1\n",
       "10574    1\n",
       "10575    0\n",
       "10576    0\n",
       "10577    0\n",
       "Name: yes, Length: 10578, dtype: uint8"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from sklearn.feature_selection import f_regression\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2., alpha=.25):\n",
    "\tdef focal_loss_fixed(y_true, y_pred):\n",
    "\t\tpt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "\t\tpt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\t\treturn -K.mean(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) - K.mean((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\treturn focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = train_data_1.astype('float')\n",
    "\n",
    "whole_data = pd.concat([train_data_1,labels], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_1, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>...</th>\n",
       "      <th>month_oct</th>\n",
       "      <th>month_sep</th>\n",
       "      <th>day_of_week_fri</th>\n",
       "      <th>day_of_week_mon</th>\n",
       "      <th>day_of_week_thu</th>\n",
       "      <th>day_of_week_tue</th>\n",
       "      <th>day_of_week_wed</th>\n",
       "      <th>poutcome_failure</th>\n",
       "      <th>poutcome_nonexistent</th>\n",
       "      <th>poutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.118584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.669135</td>\n",
       "      <td>0.338912</td>\n",
       "      <td>0.981183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882307</td>\n",
       "      <td>0.376569</td>\n",
       "      <td>0.980503</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9168</th>\n",
       "      <td>0.4375</td>\n",
       "      <td>0.067252</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.296960</td>\n",
       "      <td>0.418410</td>\n",
       "      <td>0.140104</td>\n",
       "      <td>0.425709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8466</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.033214</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.269680</td>\n",
       "      <td>0.192469</td>\n",
       "      <td>0.143278</td>\n",
       "      <td>0.512287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>0.2625</td>\n",
       "      <td>0.060115</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.4875</td>\n",
       "      <td>0.067801</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484412</td>\n",
       "      <td>0.615063</td>\n",
       "      <td>0.981637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>0.2125</td>\n",
       "      <td>0.038155</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484412</td>\n",
       "      <td>0.615063</td>\n",
       "      <td>0.981410</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484412</td>\n",
       "      <td>0.615063</td>\n",
       "      <td>0.981637</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.185561</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>0.957833</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.075487</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.340608</td>\n",
       "      <td>0.154812</td>\n",
       "      <td>0.174790</td>\n",
       "      <td>0.512287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7404 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         age  duration  campaign  pdays  previous  emp.var.rate  \\\n",
       "3233  0.2000  0.118584  0.000000    1.0       0.0      1.000000   \n",
       "2856  0.5000  0.004392  0.166667    1.0       0.0      1.000000   \n",
       "9168  0.4375  0.067252  0.023810    1.0       0.0      0.104167   \n",
       "8466  0.2500  0.033214  0.023810    1.0       0.0      0.333333   \n",
       "1219  0.2625  0.060115  0.071429    1.0       0.0      0.937500   \n",
       "...      ...       ...       ...    ...       ...           ...   \n",
       "5734  0.4875  0.067801  0.047619    1.0       0.0      1.000000   \n",
       "5191  0.2125  0.038155  0.047619    1.0       0.0      1.000000   \n",
       "5390  0.2250  0.017019  0.023810    1.0       0.0      1.000000   \n",
       "860   0.1625  0.185561  0.000000    1.0       0.0      0.937500   \n",
       "7270  0.2500  0.075487  0.000000    1.0       0.0      0.333333   \n",
       "\n",
       "      cons.price.idx  cons.conf.idx  euribor3m  nr.employed  ...  month_oct  \\\n",
       "3233        0.669135       0.338912   0.981183     1.000000  ...        0.0   \n",
       "2856        0.882307       0.376569   0.980503     1.000000  ...        0.0   \n",
       "9168        0.296960       0.418410   0.140104     0.425709  ...        0.0   \n",
       "8466        0.269680       0.192469   0.143278     0.512287  ...        0.0   \n",
       "1219        0.698753       0.602510   0.957379     0.859735  ...        0.0   \n",
       "...              ...            ...        ...          ...  ...        ...   \n",
       "5734        0.484412       0.615063   0.981637     1.000000  ...        0.0   \n",
       "5191        0.484412       0.615063   0.981410     1.000000  ...        0.0   \n",
       "5390        0.484412       0.615063   0.981637     1.000000  ...        0.0   \n",
       "860         0.698753       0.602510   0.957833     0.859735  ...        0.0   \n",
       "7270        0.340608       0.154812   0.174790     0.512287  ...        0.0   \n",
       "\n",
       "      month_sep  day_of_week_fri  day_of_week_mon  day_of_week_thu  \\\n",
       "3233        0.0              0.0              0.0              0.0   \n",
       "2856        0.0              1.0              0.0              0.0   \n",
       "9168        0.0              0.0              0.0              0.0   \n",
       "8466        0.0              0.0              0.0              1.0   \n",
       "1219        0.0              1.0              0.0              0.0   \n",
       "...         ...              ...              ...              ...   \n",
       "5734        0.0              0.0              0.0              0.0   \n",
       "5191        0.0              0.0              1.0              0.0   \n",
       "5390        0.0              0.0              0.0              0.0   \n",
       "860         0.0              1.0              0.0              0.0   \n",
       "7270        0.0              0.0              1.0              0.0   \n",
       "\n",
       "      day_of_week_tue  day_of_week_wed  poutcome_failure  \\\n",
       "3233              0.0              1.0               0.0   \n",
       "2856              0.0              0.0               0.0   \n",
       "9168              1.0              0.0               0.0   \n",
       "8466              0.0              0.0               0.0   \n",
       "1219              0.0              0.0               0.0   \n",
       "...               ...              ...               ...   \n",
       "5734              0.0              1.0               0.0   \n",
       "5191              0.0              0.0               0.0   \n",
       "5390              0.0              1.0               0.0   \n",
       "860               0.0              0.0               0.0   \n",
       "7270              0.0              0.0               0.0   \n",
       "\n",
       "      poutcome_nonexistent  poutcome_success  \n",
       "3233                   1.0               0.0  \n",
       "2856                   1.0               0.0  \n",
       "9168                   1.0               0.0  \n",
       "8466                   1.0               0.0  \n",
       "1219                   1.0               0.0  \n",
       "...                    ...               ...  \n",
       "5734                   1.0               0.0  \n",
       "5191                   1.0               0.0  \n",
       "5390                   1.0               0.0  \n",
       "860                    1.0               0.0  \n",
       "7270                   1.0               0.0  \n",
       "\n",
       "[7404 rows x 63 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "temp1 = np.asarray(train_data_1)\n",
    "x = chi2(temp1, label)\n",
    "np.shape(x)\n",
    "k = 0\n",
    "for i,j,c in zip(x[0], x[1], train_data_1.columns):\n",
    "    if j>0.1:\n",
    "        train_data_1.pop(c)\n",
    "        test_data_1.pop(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': {'auc', 'binary_logloss'},\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 1.666539574628305,\n",
       " 'lambda_l2': 1.6574680675678002e-07,\n",
       " 'num_leaves': 19,\n",
       " 'feature_fraction': 0.852,\n",
       " 'bagging_fraction': 0.9913490101029431,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 10,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 100,\n",
       " 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'binary',\n",
    " 'metric': {'auc', 'binary_logloss'},\n",
    " 'verbosity': -1,\n",
    " 'boosting_type': 'gbdt',\n",
    " 'feature_pre_filter': False,\n",
    " 'lambda_l1': 1.666539574628305,\n",
    " 'lambda_l2': 1.6574680675678002e-07,\n",
    " 'num_leaves': 19,\n",
    " 'feature_fraction': 0.852,\n",
    " 'bagging_fraction': 0.9913490101029431,\n",
    " 'bagging_freq': 7,\n",
    " 'min_child_samples': 10,\n",
    " 'num_iterations': 10000,\n",
    " 'early_stopping_round': 100}\n",
    "\n",
    "from hyperopt import fmin, tpe, hp, partial\n",
    "from sklearn.metrics import accuracy_score\n",
    "space = {\"max_depth\": hp.randint(\"max_depth\", 30),\n",
    "         #\"num_iterations\": hp.randint(\"num_trees\", 100,10000),\n",
    "         'learning_rate': hp.uniform('learning_rate', 1e-4, 5e-1),\n",
    "         #\"bagging_fraction\": hp.randint(\"bagging_fraction\", 5),\n",
    "         #\"num_leaves\": hp.randint(\"num_leaves\", 6),\n",
    "         }\n",
    "\n",
    "def lightgbm_factory(argsDict):\n",
    "    #argsDict = argsDict_tranform(argsDict)\n",
    "    \n",
    "    params = {\n",
    "            'max_depth': argsDict['max_depth'],\n",
    "            #'num_iterations': argsDict['num_iterations'],\n",
    "            'learning_rate': argsDict[\"learning_rate\"],\n",
    "            'objective': 'binary',\n",
    "             'metric': {'auc', 'binary_logloss'},\n",
    "             'verbosity': -1,\n",
    "             'boosting_type': 'gbdt',\n",
    "             'feature_pre_filter': False,\n",
    "             'lambda_l1': 1.666539574628305,\n",
    "             'lambda_l2': 1.6574680675678002e-07,\n",
    "             'num_leaves': 19,\n",
    "             'feature_fraction': 0.852,\n",
    "             'bagging_fraction': 0.9913490101029431,\n",
    "             'bagging_freq': 7,\n",
    "             'min_child_samples': 10,\n",
    "             'num_iterations': 10000,\n",
    "             'early_stopping_round': 100,\n",
    "      'is_unbalance':True}\n",
    "\n",
    "    model_lgb = lgb.train(params, train_data, valid_sets=[test_data],early_stopping_rounds=100,verbose_eval=100)\n",
    "\n",
    "    return get_tranformer_score(model_lgb)\n",
    "\n",
    "def get_tranformer_score(tranformer):\n",
    "    \n",
    "    clf = tranformer\n",
    "    prediction = np.rint(clf.predict(val, num_iteration=clf.best_iteration))\n",
    "    \n",
    "  \n",
    "    return -accuracy_score(np.asarray(val_label), prediction)\n",
    "train_data_1 = train_data_1.astype('float')\n",
    "test_data_1 = test_data_1.astype('float')\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_1, labels, test_size=0.2, random_state=42)\n",
    "train_label = np.asarray(y_train)\n",
    "val_label = np.asarray(y_test)\n",
    "data = np.asarray(X_train)\n",
    "val = np.asarray(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 1., 0.])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "  0%|                                                                          | 0/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n",
      "D:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.942671\tvalid_0's binary_logloss: 0.265278                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\tvalid_0's auc: 0.946229\tvalid_0's binary_logloss: 0.283754\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.938533\tvalid_0's binary_logloss: 0.277655                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\tvalid_0's auc: 0.946268\tvalid_0's binary_logloss: 0.285459\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.935872\tvalid_0's binary_logloss: 0.290499                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\tvalid_0's auc: 0.945609\tvalid_0's binary_logloss: 0.29084\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94648\tvalid_0's binary_logloss: 0.283389                                                        \n",
      "[200]\tvalid_0's auc: 0.94788\tvalid_0's binary_logloss: 0.278125                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[195]\tvalid_0's auc: 0.947975\tvalid_0's binary_logloss: 0.27815\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.939991\tvalid_0's binary_logloss: 0.355735                                                       \n",
      "[200]\tvalid_0's auc: 0.942738\tvalid_0's binary_logloss: 0.315745                                                       \n",
      "[300]\tvalid_0's auc: 0.944174\tvalid_0's binary_logloss: 0.29696                                                        \n",
      "[400]\tvalid_0's auc: 0.944705\tvalid_0's binary_logloss: 0.287768                                                       \n",
      "[500]\tvalid_0's auc: 0.944872\tvalid_0's binary_logloss: 0.282971                                                       \n",
      "[600]\tvalid_0's auc: 0.945173\tvalid_0's binary_logloss: 0.281345                                                       \n",
      "[700]\tvalid_0's auc: 0.945525\tvalid_0's binary_logloss: 0.280365                                                       \n",
      "[800]\tvalid_0's auc: 0.945961\tvalid_0's binary_logloss: 0.28002                                                        \n",
      "[900]\tvalid_0's auc: 0.946438\tvalid_0's binary_logloss: 0.279975                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[870]\tvalid_0's auc: 0.946323\tvalid_0's binary_logloss: 0.279865\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.936563\tvalid_0's binary_logloss: 0.445443                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[47]\tvalid_0's auc: 0.937313\tvalid_0's binary_logloss: 0.451109\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946589\tvalid_0's binary_logloss: 0.264983                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[54]\tvalid_0's auc: 0.947811\tvalid_0's binary_logloss: 0.272398\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94592\tvalid_0's binary_logloss: 0.26524                                                         \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[42]\tvalid_0's auc: 0.948542\tvalid_0's binary_logloss: 0.271948\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945155\tvalid_0's binary_logloss: 0.265533                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\tvalid_0's auc: 0.947305\tvalid_0's binary_logloss: 0.274768\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946069\tvalid_0's binary_logloss: 0.266701                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[57]\tvalid_0's auc: 0.947652\tvalid_0's binary_logloss: 0.271578\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943404\tvalid_0's binary_logloss: 0.284537                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43]\tvalid_0's auc: 0.946117\tvalid_0's binary_logloss: 0.289413\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.937794\tvalid_0's binary_logloss: 0.281129                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\tvalid_0's auc: 0.945333\tvalid_0's binary_logloss: 0.283078\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94207\tvalid_0's binary_logloss: 0.269393                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[31]\tvalid_0's auc: 0.946906\tvalid_0's binary_logloss: 0.275622\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947229\tvalid_0's binary_logloss: 0.271717                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[62]\tvalid_0's auc: 0.94755\tvalid_0's binary_logloss: 0.278114\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.940474\tvalid_0's binary_logloss: 0.271452                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\tvalid_0's auc: 0.945692\tvalid_0's binary_logloss: 0.285566\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.93583\tvalid_0's binary_logloss: 0.284607                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\tvalid_0's auc: 0.945642\tvalid_0's binary_logloss: 0.283917\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94799\tvalid_0's binary_logloss: 0.285539                                                        \n",
      "[200]\tvalid_0's auc: 0.948029\tvalid_0's binary_logloss: 0.272628                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:                                                                                     \n",
      "[138]\tvalid_0's auc: 0.94835\tvalid_0's binary_logloss: 0.278691\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946324\tvalid_0's binary_logloss: 0.26291                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\tvalid_0's auc: 0.94769\tvalid_0's binary_logloss: 0.274746\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.941497\tvalid_0's binary_logloss: 0.271194                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[26]\tvalid_0's auc: 0.9468\tvalid_0's binary_logloss: 0.280177\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947428\tvalid_0's binary_logloss: 0.268                                                          \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[53]\tvalid_0's auc: 0.948584\tvalid_0's binary_logloss: 0.2759\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94282\tvalid_0's binary_logloss: 0.267457                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\tvalid_0's auc: 0.947036\tvalid_0's binary_logloss: 0.273236\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94654\tvalid_0's binary_logloss: 0.278614                                                        \n",
      "[200]\tvalid_0's auc: 0.946169\tvalid_0's binary_logloss: 0.268865                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[137]\tvalid_0's auc: 0.946849\tvalid_0's binary_logloss: 0.273836\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943372\tvalid_0's binary_logloss: 0.26573                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\tvalid_0's auc: 0.947115\tvalid_0's binary_logloss: 0.279898\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943437\tvalid_0's binary_logloss: 0.269102                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\tvalid_0's auc: 0.947101\tvalid_0's binary_logloss: 0.282956\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942501\tvalid_0's binary_logloss: 0.306133                                                       \n",
      "[200]\tvalid_0's auc: 0.944883\tvalid_0's binary_logloss: 0.295658                                                       \n",
      "[300]\tvalid_0's auc: 0.945316\tvalid_0's binary_logloss: 0.292363                                                       \n",
      "[400]\tvalid_0's auc: 0.945783\tvalid_0's binary_logloss: 0.287321                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[350]\tvalid_0's auc: 0.946197\tvalid_0's binary_logloss: 0.286721\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945251\tvalid_0's binary_logloss: 0.265409                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\tvalid_0's auc: 0.947392\tvalid_0's binary_logloss: 0.280821\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.937541\tvalid_0's binary_logloss: 0.278439                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\tvalid_0's auc: 0.94542\tvalid_0's binary_logloss: 0.288249\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947006\tvalid_0's binary_logloss: 0.280063                                                       \n",
      "[200]\tvalid_0's auc: 0.947534\tvalid_0's binary_logloss: 0.273669                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[192]\tvalid_0's auc: 0.947844\tvalid_0's binary_logloss: 0.273863\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947366\tvalid_0's binary_logloss: 0.267264                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43]\tvalid_0's auc: 0.948266\tvalid_0's binary_logloss: 0.278453\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.938835\tvalid_0's binary_logloss: 0.325291                                                       \n",
      "[200]\tvalid_0's auc: 0.940767\tvalid_0's binary_logloss: 0.317507                                                       \n",
      "[300]\tvalid_0's auc: 0.941168\tvalid_0's binary_logloss: 0.31543                                                        \n",
      "[400]\tvalid_0's auc: 0.941512\tvalid_0's binary_logloss: 0.312452                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[391]\tvalid_0's auc: 0.941585\tvalid_0's binary_logloss: 0.312115\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943268\tvalid_0's binary_logloss: 0.266496                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\tvalid_0's auc: 0.947455\tvalid_0's binary_logloss: 0.27962\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942448\tvalid_0's binary_logloss: 0.266989                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\tvalid_0's auc: 0.947275\tvalid_0's binary_logloss: 0.281099\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.938164\tvalid_0's binary_logloss: 0.278791                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\tvalid_0's auc: 0.946605\tvalid_0's binary_logloss: 0.283229\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94668\tvalid_0's binary_logloss: 0.280737                                                        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:                                                                                     \n",
      "[75]\tvalid_0's auc: 0.947484\tvalid_0's binary_logloss: 0.282751\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943437\tvalid_0's binary_logloss: 0.272692                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[35]\tvalid_0's auc: 0.947209\tvalid_0's binary_logloss: 0.280238\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946047\tvalid_0's binary_logloss: 0.280174                                                       \n",
      "[200]\tvalid_0's auc: 0.947632\tvalid_0's binary_logloss: 0.278047                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[179]\tvalid_0's auc: 0.947926\tvalid_0's binary_logloss: 0.278636\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942806\tvalid_0's binary_logloss: 0.269515                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\tvalid_0's auc: 0.94622\tvalid_0's binary_logloss: 0.282804\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.936485\tvalid_0's binary_logloss: 0.441822                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[46]\tvalid_0's auc: 0.937282\tvalid_0's binary_logloss: 0.44945\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942923\tvalid_0's binary_logloss: 0.266778                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\tvalid_0's auc: 0.946879\tvalid_0's binary_logloss: 0.285096\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.939539\tvalid_0's binary_logloss: 0.273599                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\tvalid_0's auc: 0.946084\tvalid_0's binary_logloss: 0.27552\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945446\tvalid_0's binary_logloss: 0.267675                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\tvalid_0's auc: 0.947497\tvalid_0's binary_logloss: 0.282564\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947395\tvalid_0's binary_logloss: 0.278493                                                       \n",
      "[200]\tvalid_0's auc: 0.947355\tvalid_0's binary_logloss: 0.269044                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[119]\tvalid_0's auc: 0.947874\tvalid_0's binary_logloss: 0.275887\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94518\tvalid_0's binary_logloss: 0.267894                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\tvalid_0's auc: 0.946987\tvalid_0's binary_logloss: 0.278874\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946918\tvalid_0's binary_logloss: 0.289884                                                       \n",
      "[200]\tvalid_0's auc: 0.947407\tvalid_0's binary_logloss: 0.281571                                                       \n",
      "[300]\tvalid_0's auc: 0.947365\tvalid_0's binary_logloss: 0.275965                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[264]\tvalid_0's auc: 0.947853\tvalid_0's binary_logloss: 0.276349\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947877\tvalid_0's binary_logloss: 0.273431                                                       \n",
      "[200]\tvalid_0's auc: 0.946966\tvalid_0's binary_logloss: 0.264112                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[103]\tvalid_0's auc: 0.948032\tvalid_0's binary_logloss: 0.272748\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946608\tvalid_0's binary_logloss: 0.266514                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[53]\tvalid_0's auc: 0.948307\tvalid_0's binary_logloss: 0.273218\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944348\tvalid_0's binary_logloss: 0.265774                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[28]\tvalid_0's auc: 0.947029\tvalid_0's binary_logloss: 0.279026\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.935834\tvalid_0's binary_logloss: 0.287343                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[12]\tvalid_0's auc: 0.946257\tvalid_0's binary_logloss: 0.279536\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942127\tvalid_0's binary_logloss: 0.266946                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[52]\tvalid_0's auc: 0.945613\tvalid_0's binary_logloss: 0.26828\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.940213\tvalid_0's binary_logloss: 0.275843                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\tvalid_0's auc: 0.947167\tvalid_0's binary_logloss: 0.283488\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945506\tvalid_0's binary_logloss: 0.270396                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[43]\tvalid_0's auc: 0.948238\tvalid_0's binary_logloss: 0.27607\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's auc: 0.943559\tvalid_0's binary_logloss: 0.26592                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[18]\tvalid_0's auc: 0.94598\tvalid_0's binary_logloss: 0.279389\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942654\tvalid_0's binary_logloss: 0.26742                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\tvalid_0's auc: 0.946784\tvalid_0's binary_logloss: 0.280272\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.938693\tvalid_0's binary_logloss: 0.275942                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\tvalid_0's auc: 0.944471\tvalid_0's binary_logloss: 0.27358\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.940915\tvalid_0's binary_logloss: 0.269996                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\tvalid_0's auc: 0.94712\tvalid_0's binary_logloss: 0.278262\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.937092\tvalid_0's binary_logloss: 0.278723                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\tvalid_0's auc: 0.945463\tvalid_0's binary_logloss: 0.287044\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.935164\tvalid_0's binary_logloss: 0.290041                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\tvalid_0's auc: 0.945201\tvalid_0's binary_logloss: 0.288841\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.939773\tvalid_0's binary_logloss: 0.274179                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[10]\tvalid_0's auc: 0.945969\tvalid_0's binary_logloss: 0.287555\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945021\tvalid_0's binary_logloss: 0.294414                                                       \n",
      "[200]\tvalid_0's auc: 0.945982\tvalid_0's binary_logloss: 0.286122                                                       \n",
      "[300]\tvalid_0's auc: 0.94595\tvalid_0's binary_logloss: 0.282494                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[220]\tvalid_0's auc: 0.946601\tvalid_0's binary_logloss: 0.283747\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.937951\tvalid_0's binary_logloss: 0.276407                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[16]\tvalid_0's auc: 0.944081\tvalid_0's binary_logloss: 0.285653\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.938596\tvalid_0's binary_logloss: 0.27994                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[7]\tvalid_0's auc: 0.945101\tvalid_0's binary_logloss: 0.289477\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.938772\tvalid_0's binary_logloss: 0.274049                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\tvalid_0's auc: 0.947206\tvalid_0's binary_logloss: 0.283045\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942241\tvalid_0's binary_logloss: 0.269834                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\tvalid_0's auc: 0.947469\tvalid_0's binary_logloss: 0.278444\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.937598\tvalid_0's binary_logloss: 0.278613                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[11]\tvalid_0's auc: 0.946668\tvalid_0's binary_logloss: 0.284032\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.939556\tvalid_0's binary_logloss: 0.276425                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[9]\tvalid_0's auc: 0.946282\tvalid_0's binary_logloss: 0.285449\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944704\tvalid_0's binary_logloss: 0.296239                                                       \n",
      "[200]\tvalid_0's auc: 0.945544\tvalid_0's binary_logloss: 0.285985                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[190]\tvalid_0's auc: 0.945846\tvalid_0's binary_logloss: 0.286404\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943978\tvalid_0's binary_logloss: 0.26733                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\tvalid_0's auc: 0.94685\tvalid_0's binary_logloss: 0.281959\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945322\tvalid_0's binary_logloss: 0.294759                                                       \n",
      "[200]\tvalid_0's auc: 0.945789\tvalid_0's binary_logloss: 0.285198                                                       \n",
      "[300]\tvalid_0's auc: 0.945889\tvalid_0's binary_logloss: 0.283495                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[220]\tvalid_0's auc: 0.946283\tvalid_0's binary_logloss: 0.283841\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.936299\tvalid_0's binary_logloss: 0.333337                                                       \n",
      "[200]\tvalid_0's auc: 0.93965\tvalid_0's binary_logloss: 0.321897                                                        \n",
      "[300]\tvalid_0's auc: 0.940619\tvalid_0's binary_logloss: 0.318247                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's auc: 0.940999\tvalid_0's binary_logloss: 0.316523                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[348]\tvalid_0's auc: 0.941072\tvalid_0's binary_logloss: 0.315428\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942755\tvalid_0's binary_logloss: 0.266948                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[33]\tvalid_0's auc: 0.945807\tvalid_0's binary_logloss: 0.27438\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.941111\tvalid_0's binary_logloss: 0.270708                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\tvalid_0's auc: 0.946649\tvalid_0's binary_logloss: 0.283126\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.939117\tvalid_0's binary_logloss: 0.278937                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[14]\tvalid_0's auc: 0.946325\tvalid_0's binary_logloss: 0.282591\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94536\tvalid_0's binary_logloss: 0.275042                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\tvalid_0's auc: 0.947187\tvalid_0's binary_logloss: 0.284364\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94576\tvalid_0's binary_logloss: 0.292722                                                        \n",
      "[200]\tvalid_0's auc: 0.94571\tvalid_0's binary_logloss: 0.283331                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[142]\tvalid_0's auc: 0.94662\tvalid_0's binary_logloss: 0.286354\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943592\tvalid_0's binary_logloss: 0.264266                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\tvalid_0's auc: 0.948626\tvalid_0's binary_logloss: 0.266617\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.940472\tvalid_0's binary_logloss: 0.269962                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\tvalid_0's auc: 0.945258\tvalid_0's binary_logloss: 0.281069\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944013\tvalid_0's binary_logloss: 0.264265                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\tvalid_0's auc: 0.947122\tvalid_0's binary_logloss: 0.279923\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.93774\tvalid_0's binary_logloss: 0.276761                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[6]\tvalid_0's auc: 0.944174\tvalid_0's binary_logloss: 0.287284\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945343\tvalid_0's binary_logloss: 0.266536                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[51]\tvalid_0's auc: 0.947755\tvalid_0's binary_logloss: 0.270721\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.947433\tvalid_0's binary_logloss: 0.272575                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[95]\tvalid_0's auc: 0.947652\tvalid_0's binary_logloss: 0.273425\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943736\tvalid_0's binary_logloss: 0.266449                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[55]\tvalid_0's auc: 0.946574\tvalid_0's binary_logloss: 0.269389\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943174\tvalid_0's binary_logloss: 0.270141                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[19]\tvalid_0's auc: 0.946987\tvalid_0's binary_logloss: 0.283026\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946161\tvalid_0's binary_logloss: 0.263433                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\tvalid_0's auc: 0.947875\tvalid_0's binary_logloss: 0.280401\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945104\tvalid_0's binary_logloss: 0.262545                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[25]\tvalid_0's auc: 0.947653\tvalid_0's binary_logloss: 0.27991\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946759\tvalid_0's binary_logloss: 0.27158                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[52]\tvalid_0's auc: 0.94778\tvalid_0's binary_logloss: 0.278111\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945009\tvalid_0's binary_logloss: 0.274722                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[40]\tvalid_0's auc: 0.947229\tvalid_0's binary_logloss: 0.28345\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944818\tvalid_0's binary_logloss: 0.282018                                                       \n",
      "[200]\tvalid_0's auc: 0.947092\tvalid_0's binary_logloss: 0.281608                                                       \n",
      "[300]\tvalid_0's auc: 0.947467\tvalid_0's binary_logloss: 0.278869                                                       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:                                                                                     \n",
      "[279]\tvalid_0's auc: 0.947678\tvalid_0's binary_logloss: 0.279113\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946956\tvalid_0's binary_logloss: 0.277451                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[79]\tvalid_0's auc: 0.947549\tvalid_0's binary_logloss: 0.278995\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944829\tvalid_0's binary_logloss: 0.267936                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[41]\tvalid_0's auc: 0.947006\tvalid_0's binary_logloss: 0.27665\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.94232\tvalid_0's binary_logloss: 0.266603                                                        \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\tvalid_0's auc: 0.947689\tvalid_0's binary_logloss: 0.2744\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945865\tvalid_0's binary_logloss: 0.266807                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[61]\tvalid_0's auc: 0.947396\tvalid_0's binary_logloss: 0.271216\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.946404\tvalid_0's binary_logloss: 0.282754                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[91]\tvalid_0's auc: 0.946729\tvalid_0's binary_logloss: 0.28326\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944585\tvalid_0's binary_logloss: 0.265851                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[45]\tvalid_0's auc: 0.947999\tvalid_0's binary_logloss: 0.270072\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943411\tvalid_0's binary_logloss: 0.268733                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[23]\tvalid_0's auc: 0.947027\tvalid_0's binary_logloss: 0.281626\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944247\tvalid_0's binary_logloss: 0.265769                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[38]\tvalid_0's auc: 0.947758\tvalid_0's binary_logloss: 0.271542\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.941521\tvalid_0's binary_logloss: 0.267482                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[21]\tvalid_0's auc: 0.946978\tvalid_0's binary_logloss: 0.276714\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.943872\tvalid_0's binary_logloss: 0.266514                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[20]\tvalid_0's auc: 0.947006\tvalid_0's binary_logloss: 0.281652\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.942318\tvalid_0's binary_logloss: 0.266606                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[24]\tvalid_0's auc: 0.947686\tvalid_0's binary_logloss: 0.274397\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.945621\tvalid_0's binary_logloss: 0.268491                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[61]\tvalid_0's auc: 0.947909\tvalid_0's binary_logloss: 0.270617\n",
      "Training until validation scores don't improve for 100 rounds                                                          \n",
      "[100]\tvalid_0's auc: 0.944475\tvalid_0's binary_logloss: 0.269757                                                       \n",
      "Early stopping, best iteration is:                                                                                     \n",
      "[49]\tvalid_0's auc: 0.947439\tvalid_0's binary_logloss: 0.275632\n",
      "100%|█████████████████████████████████████████████| 100/100 [00:42<00:00,  2.36trial/s, best loss: -0.8761814744801513]\n"
     ]
    }
   ],
   "source": [
    "train_data = lgb.Dataset(data=data, label = train_label)\n",
    "test_data = lgb.Dataset(data=val, label=val_label)\n",
    "\n",
    "algo = partial(tpe.suggest, n_startup_jobs=1)\n",
    "best = fmin(lightgbm_factory, space, algo=algo, max_evals=100, pass_expr_memo_ctrl=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.23118001060848284, 'max_depth': 14}"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        'max_depth': 14,\n",
    "        #'num_iterations': argsDict['num_iterations'],\n",
    "        'learning_rate': best[\"learning_rate\"]/10,\n",
    "        'objective': 'binary',\n",
    "         'metric': {'auc', 'binary_logloss'},\n",
    "         'verbosity': -1,\n",
    "         'boosting_type': 'gbdt',\n",
    "         'feature_pre_filter': False,\n",
    "         'lambda_l1': 1.666539574628305,\n",
    "         'lambda_l2': 1.6574680675678002e-07,\n",
    "         'num_leaves': 19,\n",
    "         'feature_fraction': 0.852,\n",
    "         'bagging_fraction': 0.9913490101029431,\n",
    "         'bagging_freq': 7,\n",
    "         'min_child_samples': 10,\n",
    "         'num_iterations': 10000,\n",
    "         'early_stopping_round': 100,\n",
    "            'is_unbalance':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttraining's auc: 0.946997\ttraining's binary_logloss: 0.339654\tvalid_1's auc: 0.932491\tvalid_1's binary_logloss: 0.342397\n",
      "[40]\ttraining's auc: 0.950899\ttraining's binary_logloss: 0.294947\tvalid_1's auc: 0.937457\tvalid_1's binary_logloss: 0.304623\n",
      "[60]\ttraining's auc: 0.952781\ttraining's binary_logloss: 0.280268\tvalid_1's auc: 0.940969\tvalid_1's binary_logloss: 0.294056\n",
      "[80]\ttraining's auc: 0.954505\ttraining's binary_logloss: 0.274647\tvalid_1's auc: 0.942673\tvalid_1's binary_logloss: 0.292077\n",
      "[100]\ttraining's auc: 0.955727\ttraining's binary_logloss: 0.2712\tvalid_1's auc: 0.943163\tvalid_1's binary_logloss: 0.291992\n",
      "[120]\ttraining's auc: 0.957339\ttraining's binary_logloss: 0.268758\tvalid_1's auc: 0.943861\tvalid_1's binary_logloss: 0.292813\n",
      "[140]\ttraining's auc: 0.959067\ttraining's binary_logloss: 0.266016\tvalid_1's auc: 0.944088\tvalid_1's binary_logloss: 0.294297\n",
      "[160]\ttraining's auc: 0.960733\ttraining's binary_logloss: 0.262696\tvalid_1's auc: 0.94459\tvalid_1's binary_logloss: 0.294464\n",
      "[180]\ttraining's auc: 0.962446\ttraining's binary_logloss: 0.258989\tvalid_1's auc: 0.945018\tvalid_1's binary_logloss: 0.2941\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.954623\ttraining's binary_logloss: 0.273539\tvalid_1's auc: 0.942878\tvalid_1's binary_logloss: 0.291527\n",
      "fold 2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttraining's auc: 0.943681\ttraining's binary_logloss: 0.327865\tvalid_1's auc: 0.940488\tvalid_1's binary_logloss: 0.342264\n",
      "[40]\ttraining's auc: 0.948442\ttraining's binary_logloss: 0.290093\tvalid_1's auc: 0.942066\tvalid_1's binary_logloss: 0.30325\n",
      "[60]\ttraining's auc: 0.950239\ttraining's binary_logloss: 0.275674\tvalid_1's auc: 0.943088\tvalid_1's binary_logloss: 0.288324\n",
      "[80]\ttraining's auc: 0.952829\ttraining's binary_logloss: 0.271581\tvalid_1's auc: 0.944068\tvalid_1's binary_logloss: 0.284719\n",
      "[100]\ttraining's auc: 0.954793\ttraining's binary_logloss: 0.268842\tvalid_1's auc: 0.944942\tvalid_1's binary_logloss: 0.28296\n",
      "[120]\ttraining's auc: 0.956756\ttraining's binary_logloss: 0.267031\tvalid_1's auc: 0.945348\tvalid_1's binary_logloss: 0.282784\n",
      "[140]\ttraining's auc: 0.958739\ttraining's binary_logloss: 0.265025\tvalid_1's auc: 0.945995\tvalid_1's binary_logloss: 0.28275\n",
      "[160]\ttraining's auc: 0.960492\ttraining's binary_logloss: 0.261902\tvalid_1's auc: 0.945732\tvalid_1's binary_logloss: 0.282609\n",
      "[180]\ttraining's auc: 0.962219\ttraining's binary_logloss: 0.258453\tvalid_1's auc: 0.946158\tvalid_1's binary_logloss: 0.281306\n",
      "[200]\ttraining's auc: 0.963807\ttraining's binary_logloss: 0.254646\tvalid_1's auc: 0.946425\tvalid_1's binary_logloss: 0.280414\n",
      "[220]\ttraining's auc: 0.96514\ttraining's binary_logloss: 0.25085\tvalid_1's auc: 0.946666\tvalid_1's binary_logloss: 0.279066\n",
      "[240]\ttraining's auc: 0.966451\ttraining's binary_logloss: 0.247111\tvalid_1's auc: 0.946722\tvalid_1's binary_logloss: 0.277827\n",
      "[260]\ttraining's auc: 0.967726\ttraining's binary_logloss: 0.243402\tvalid_1's auc: 0.946546\tvalid_1's binary_logloss: 0.27698\n",
      "[280]\ttraining's auc: 0.968889\ttraining's binary_logloss: 0.23957\tvalid_1's auc: 0.946521\tvalid_1's binary_logloss: 0.275896\n",
      "[300]\ttraining's auc: 0.970311\ttraining's binary_logloss: 0.235534\tvalid_1's auc: 0.946239\tvalid_1's binary_logloss: 0.275285\n",
      "[320]\ttraining's auc: 0.971428\ttraining's binary_logloss: 0.232114\tvalid_1's auc: 0.946146\tvalid_1's binary_logloss: 0.274464\n",
      "[340]\ttraining's auc: 0.972622\ttraining's binary_logloss: 0.22818\tvalid_1's auc: 0.946012\tvalid_1's binary_logloss: 0.273458\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's auc: 0.966714\ttraining's binary_logloss: 0.246373\tvalid_1's auc: 0.946853\tvalid_1's binary_logloss: 0.277428\n",
      "fold 3\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttraining's auc: 0.946026\ttraining's binary_logloss: 0.344021\tvalid_1's auc: 0.938637\tvalid_1's binary_logloss: 0.334773\n",
      "[40]\ttraining's auc: 0.948312\ttraining's binary_logloss: 0.29833\tvalid_1's auc: 0.940679\tvalid_1's binary_logloss: 0.295471\n",
      "[60]\ttraining's auc: 0.950597\ttraining's binary_logloss: 0.283097\tvalid_1's auc: 0.942624\tvalid_1's binary_logloss: 0.283768\n",
      "[80]\ttraining's auc: 0.952655\ttraining's binary_logloss: 0.2774\tvalid_1's auc: 0.94364\tvalid_1's binary_logloss: 0.281296\n",
      "[100]\ttraining's auc: 0.95437\ttraining's binary_logloss: 0.273786\tvalid_1's auc: 0.944735\tvalid_1's binary_logloss: 0.28022\n",
      "[120]\ttraining's auc: 0.956375\ttraining's binary_logloss: 0.271053\tvalid_1's auc: 0.945308\tvalid_1's binary_logloss: 0.280347\n",
      "[140]\ttraining's auc: 0.957906\ttraining's binary_logloss: 0.268347\tvalid_1's auc: 0.94573\tvalid_1's binary_logloss: 0.280727\n",
      "[160]\ttraining's auc: 0.959732\ttraining's binary_logloss: 0.265205\tvalid_1's auc: 0.946092\tvalid_1's binary_logloss: 0.280716\n",
      "[180]\ttraining's auc: 0.961117\ttraining's binary_logloss: 0.261936\tvalid_1's auc: 0.946202\tvalid_1's binary_logloss: 0.280308\n",
      "[200]\ttraining's auc: 0.962813\ttraining's binary_logloss: 0.258387\tvalid_1's auc: 0.946417\tvalid_1's binary_logloss: 0.280071\n",
      "[220]\ttraining's auc: 0.964257\ttraining's binary_logloss: 0.254752\tvalid_1's auc: 0.946616\tvalid_1's binary_logloss: 0.279313\n",
      "[240]\ttraining's auc: 0.965708\ttraining's binary_logloss: 0.250323\tvalid_1's auc: 0.946919\tvalid_1's binary_logloss: 0.277666\n",
      "[260]\ttraining's auc: 0.967139\ttraining's binary_logloss: 0.24642\tvalid_1's auc: 0.94684\tvalid_1's binary_logloss: 0.276994\n",
      "[280]\ttraining's auc: 0.968378\ttraining's binary_logloss: 0.242961\tvalid_1's auc: 0.947049\tvalid_1's binary_logloss: 0.27621\n",
      "[300]\ttraining's auc: 0.969598\ttraining's binary_logloss: 0.23902\tvalid_1's auc: 0.947214\tvalid_1's binary_logloss: 0.274573\n",
      "[320]\ttraining's auc: 0.970739\ttraining's binary_logloss: 0.235389\tvalid_1's auc: 0.947257\tvalid_1's binary_logloss: 0.273414\n",
      "[340]\ttraining's auc: 0.971855\ttraining's binary_logloss: 0.231809\tvalid_1's auc: 0.947218\tvalid_1's binary_logloss: 0.27242\n",
      "[360]\ttraining's auc: 0.972938\ttraining's binary_logloss: 0.228779\tvalid_1's auc: 0.947052\tvalid_1's binary_logloss: 0.27206\n",
      "[380]\ttraining's auc: 0.973957\ttraining's binary_logloss: 0.225541\tvalid_1's auc: 0.946919\tvalid_1's binary_logloss: 0.271546\n",
      "[400]\ttraining's auc: 0.974812\ttraining's binary_logloss: 0.222419\tvalid_1's auc: 0.946963\tvalid_1's binary_logloss: 0.270879\n",
      "[420]\ttraining's auc: 0.975583\ttraining's binary_logloss: 0.219759\tvalid_1's auc: 0.946754\tvalid_1's binary_logloss: 0.270454\n",
      "Early stopping, best iteration is:\n",
      "[338]\ttraining's auc: 0.971744\ttraining's binary_logloss: 0.232127\tvalid_1's auc: 0.947302\tvalid_1's binary_logloss: 0.272412\n",
      "fold 4\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttraining's auc: 0.945477\ttraining's binary_logloss: 0.329418\tvalid_1's auc: 0.938819\tvalid_1's binary_logloss: 0.339131\n",
      "[40]\ttraining's auc: 0.949338\ttraining's binary_logloss: 0.291195\tvalid_1's auc: 0.940145\tvalid_1's binary_logloss: 0.302202\n",
      "[60]\ttraining's auc: 0.951364\ttraining's binary_logloss: 0.275607\tvalid_1's auc: 0.941222\tvalid_1's binary_logloss: 0.289317\n",
      "[80]\ttraining's auc: 0.953834\ttraining's binary_logloss: 0.270873\tvalid_1's auc: 0.942194\tvalid_1's binary_logloss: 0.287707\n",
      "[100]\ttraining's auc: 0.955832\ttraining's binary_logloss: 0.268121\tvalid_1's auc: 0.9427\tvalid_1's binary_logloss: 0.288576\n",
      "[120]\ttraining's auc: 0.957958\ttraining's binary_logloss: 0.265363\tvalid_1's auc: 0.943263\tvalid_1's binary_logloss: 0.289272\n",
      "[140]\ttraining's auc: 0.959523\ttraining's binary_logloss: 0.262747\tvalid_1's auc: 0.942852\tvalid_1's binary_logloss: 0.291263\n",
      "[160]\ttraining's auc: 0.960965\ttraining's binary_logloss: 0.259914\tvalid_1's auc: 0.943351\tvalid_1's binary_logloss: 0.291322\n",
      "[180]\ttraining's auc: 0.962616\ttraining's binary_logloss: 0.256751\tvalid_1's auc: 0.943634\tvalid_1's binary_logloss: 0.291036\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's auc: 0.953967\ttraining's binary_logloss: 0.270372\tvalid_1's auc: 0.94227\tvalid_1's binary_logloss: 0.287502\n",
      "fold 5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[20]\ttraining's auc: 0.945496\ttraining's binary_logloss: 0.330381\tvalid_1's auc: 0.934785\tvalid_1's binary_logloss: 0.3352\n",
      "[40]\ttraining's auc: 0.948561\ttraining's binary_logloss: 0.291628\tvalid_1's auc: 0.938034\tvalid_1's binary_logloss: 0.300467\n",
      "[60]\ttraining's auc: 0.950616\ttraining's binary_logloss: 0.275944\tvalid_1's auc: 0.939519\tvalid_1's binary_logloss: 0.287375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\ttraining's auc: 0.953247\ttraining's binary_logloss: 0.271045\tvalid_1's auc: 0.940414\tvalid_1's binary_logloss: 0.285162\n",
      "[100]\ttraining's auc: 0.955088\ttraining's binary_logloss: 0.268231\tvalid_1's auc: 0.940632\tvalid_1's binary_logloss: 0.28557\n",
      "[120]\ttraining's auc: 0.957063\ttraining's binary_logloss: 0.265846\tvalid_1's auc: 0.941907\tvalid_1's binary_logloss: 0.286093\n",
      "[140]\ttraining's auc: 0.95868\ttraining's binary_logloss: 0.264019\tvalid_1's auc: 0.942408\tvalid_1's binary_logloss: 0.286891\n",
      "[160]\ttraining's auc: 0.960498\ttraining's binary_logloss: 0.261203\tvalid_1's auc: 0.942432\tvalid_1's binary_logloss: 0.287543\n",
      "[180]\ttraining's auc: 0.962224\ttraining's binary_logloss: 0.258033\tvalid_1's auc: 0.942826\tvalid_1's binary_logloss: 0.28761\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's auc: 0.953409\ttraining's binary_logloss: 0.270615\tvalid_1's auc: 0.940365\tvalid_1's binary_logloss: 0.285018\n"
     ]
    }
   ],
   "source": [
    "feature_importance_df = pd.DataFrame()\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "prob_oof = np.zeros((train_data_1.shape[0], ))\n",
    "test_pred_prob = np.zeros((test_data_1.shape[0], ))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data_1)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(train_data_1.iloc[trn_idx], label=labels[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data_1.iloc[val_idx], label=labels[val_idx])\n",
    "\n",
    "\n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=20,\n",
    "                    early_stopping_rounds=100)\n",
    "    \n",
    "    prob_oof[val_idx] = clf.predict(train_data_1.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = list(train_data_1.columns)\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    test_pred_prob += clf.predict(test_data_1, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15929,)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(15929):\n",
    "    if test_pred_prob[i]<0.5:\n",
    "        test_pred_prob[i] = 0\n",
    "    else:\n",
    "        test_pred_prob[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('SampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = dict()\n",
    "for id, result in enumerate(test_pred_prob):\n",
    "    if result == 0:\n",
    "        submit.iloc[id,1] = 'No'\n",
    "    else:\n",
    "        submit.iloc[id,1] = 'yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.index = submit['SampleId']\n",
    "submit.pop('SampleId')\n",
    "submit.to_csv('submit_to_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": 'binary_logloss',\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    'nthread': 8,\n",
    "    'num_iterations': 10000,\n",
    "    \"random_state\": 1\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train,val,train_label,val_label = train_test_split(train_data_1, label, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": 'binary_logloss',\n",
    "    \"verbosity\": -1,\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job_admin.</th>\n",
       "      <th>...</th>\n",
       "      <th>day_of_week_fripoutcome_success</th>\n",
       "      <th>day_of_week_monpoutcome_nonexistent</th>\n",
       "      <th>day_of_week_monpoutcome_success</th>\n",
       "      <th>day_of_week_thupoutcome_nonexistent</th>\n",
       "      <th>day_of_week_thupoutcome_success</th>\n",
       "      <th>day_of_week_tuepoutcome_nonexistent</th>\n",
       "      <th>day_of_week_tuepoutcome_success</th>\n",
       "      <th>day_of_week_wedpoutcome_failure</th>\n",
       "      <th>day_of_week_wedpoutcome_nonexistent</th>\n",
       "      <th>day_of_week_wedpoutcome_success</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.084271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.038155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.698753</td>\n",
       "      <td>0.60251</td>\n",
       "      <td>0.957379</td>\n",
       "      <td>0.859735</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10573</th>\n",
       "      <td>0.096898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.090002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10574</th>\n",
       "      <td>0.132583</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.006006</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.090002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10575</th>\n",
       "      <td>0.069723</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10576</th>\n",
       "      <td>0.105133</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10577</th>\n",
       "      <td>0.065605</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.089322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10578 rows × 758 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       duration  campaign     pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0      0.071644  0.000000  1.000000  0.000000      0.937500        0.698753   \n",
       "1      0.062037  0.000000  1.000000  0.000000      0.937500        0.698753   \n",
       "2      0.084271  0.000000  1.000000  0.000000      0.937500        0.698753   \n",
       "3      0.038155  0.000000  1.000000  0.000000      0.937500        0.698753   \n",
       "4      0.013725  0.000000  1.000000  0.000000      0.937500        0.698753   \n",
       "...         ...       ...       ...       ...           ...             ...   \n",
       "10573  0.096898  0.000000  1.000000  0.000000      0.479167        1.000000   \n",
       "10574  0.132583  0.023810  0.006006  0.500000      0.479167        1.000000   \n",
       "10575  0.069723  0.023810  1.000000  0.000000      0.479167        1.000000   \n",
       "10576  0.105133  0.000000  1.000000  0.000000      0.479167        1.000000   \n",
       "10577  0.065605  0.047619  1.000000  0.166667      0.479167        1.000000   \n",
       "\n",
       "       cons.conf.idx  euribor3m  nr.employed  job_admin.  ...  \\\n",
       "0            0.60251   0.957379     0.859735           0  ...   \n",
       "1            0.60251   0.957379     0.859735           0  ...   \n",
       "2            0.60251   0.957379     0.859735           0  ...   \n",
       "3            0.60251   0.957379     0.859735           1  ...   \n",
       "4            0.60251   0.957379     0.859735           0  ...   \n",
       "...              ...        ...          ...         ...  ...   \n",
       "10573        0.00000   0.090002     0.000000           1  ...   \n",
       "10574        0.00000   0.090002     0.000000           0  ...   \n",
       "10575        0.00000   0.089322     0.000000           1  ...   \n",
       "10576        0.00000   0.089322     0.000000           0  ...   \n",
       "10577        0.00000   0.089322     0.000000           0  ...   \n",
       "\n",
       "       day_of_week_fripoutcome_success  day_of_week_monpoutcome_nonexistent  \\\n",
       "0                                    0                                    1   \n",
       "1                                    0                                    1   \n",
       "2                                    0                                    1   \n",
       "3                                    0                                    1   \n",
       "4                                    0                                    1   \n",
       "...                                ...                                  ...   \n",
       "10573                                0                                    0   \n",
       "10574                                0                                    0   \n",
       "10575                                0                                    0   \n",
       "10576                                0                                    0   \n",
       "10577                                0                                    0   \n",
       "\n",
       "       day_of_week_monpoutcome_success  day_of_week_thupoutcome_nonexistent  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "...                                ...                                  ...   \n",
       "10573                                0                                    1   \n",
       "10574                                0                                    0   \n",
       "10575                                0                                    0   \n",
       "10576                                0                                    0   \n",
       "10577                                0                                    0   \n",
       "\n",
       "       day_of_week_thupoutcome_success  day_of_week_tuepoutcome_nonexistent  \\\n",
       "0                                    0                                    0   \n",
       "1                                    0                                    0   \n",
       "2                                    0                                    0   \n",
       "3                                    0                                    0   \n",
       "4                                    0                                    0   \n",
       "...                                ...                                  ...   \n",
       "10573                                0                                    0   \n",
       "10574                                1                                    0   \n",
       "10575                                0                                    0   \n",
       "10576                                0                                    0   \n",
       "10577                                0                                    0   \n",
       "\n",
       "       day_of_week_tuepoutcome_success  day_of_week_wedpoutcome_failure  \\\n",
       "0                                    0                                0   \n",
       "1                                    0                                0   \n",
       "2                                    0                                0   \n",
       "3                                    0                                0   \n",
       "4                                    0                                0   \n",
       "...                                ...                              ...   \n",
       "10573                                0                                0   \n",
       "10574                                0                                0   \n",
       "10575                                0                                0   \n",
       "10576                                0                                0   \n",
       "10577                                0                                0   \n",
       "\n",
       "       day_of_week_wedpoutcome_nonexistent  day_of_week_wedpoutcome_success  \n",
       "0                                        0                                0  \n",
       "1                                        0                                0  \n",
       "2                                        0                                0  \n",
       "3                                        0                                0  \n",
       "4                                        0                                0  \n",
       "...                                    ...                              ...  \n",
       "10573                                    0                                0  \n",
       "10574                                    0                                0  \n",
       "10575                                    0                                0  \n",
       "10576                                    0                                0  \n",
       "10577                                    0                                0  \n",
       "\n",
       "[10578 rows x 758 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-04 22:26:19,258]\u001b[0m A new study created in memory with name: no-name-2cba8d12-c204-45c2-8126-87fdbdf75df1\u001b[0m\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: inf:   0%|                                                          | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.130831\tvalid_1's binary_logloss: 0.230654\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's binary_logloss: 0.135662\tvalid_1's binary_logloss: 0.229954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.229954:   0%|                                                     | 0/7 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.229954:  14%|######4                                      | 1/7 [00:00<00:03,  1.56it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:19,909]\u001b[0m Trial 0 finished with value: 0.22995400175516592 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.22995400175516592.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.229954:  14%|######4                                      | 1/7 [00:00<00:03,  1.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  14%|######4                                      | 1/7 [00:01<00:03,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  29%|############8                                | 2/7 [00:01<00:02,  1.69it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:20,467]\u001b[0m Trial 1 finished with value: 0.22359197141263126 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.22359197141263126.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  29%|############8                                | 2/7 [00:01<00:02,  1.69it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.116236\tvalid_1's binary_logloss: 0.231623\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's binary_logloss: 0.163867\tvalid_1's binary_logloss: 0.223592\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  29%|############8                                | 2/7 [00:01<00:02,  1.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  43%|###################2                         | 3/7 [00:01<00:02,  1.64it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:21,100]\u001b[0m Trial 2 finished with value: 0.22714907796929543 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.22359197141263126.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  43%|###################2                         | 3/7 [00:01<00:02,  1.64it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.126365\tvalid_1's binary_logloss: 0.23058\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's binary_logloss: 0.148029\tvalid_1's binary_logloss: 0.227149\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  43%|###################2                         | 3/7 [00:02<00:02,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  57%|#########################7                   | 4/7 [00:02<00:01,  1.68it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:21,673]\u001b[0m Trial 3 finished with value: 0.22403241285889952 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.22359197141263126.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  57%|#########################7                   | 4/7 [00:02<00:01,  1.68it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.113814\tvalid_1's binary_logloss: 0.233434\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's binary_logloss: 0.163341\tvalid_1's binary_logloss: 0.224032\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  57%|#########################7                   | 4/7 [00:02<00:01,  1.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  71%|################################1            | 5/7 [00:02<00:01,  1.70it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:22,243]\u001b[0m Trial 4 finished with value: 0.22439743797954623 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.22359197141263126.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223592:  71%|################################1            | 5/7 [00:02<00:01,  1.70it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.119868\tvalid_1's binary_logloss: 0.22875\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's binary_logloss: 0.149267\tvalid_1's binary_logloss: 0.224397\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223029:  71%|################################1            | 5/7 [00:03<00:01,  1.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.223029:  86%|######################################5      | 6/7 [00:03<00:00,  1.74it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:22,791]\u001b[0m Trial 5 finished with value: 0.2230286881679849 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 5 with value: 0.2230286881679849.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223029:  86%|######################################5      | 6/7 [00:03<00:00,  1.74it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.114173\tvalid_1's binary_logloss: 0.232266\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's binary_logloss: 0.169047\tvalid_1's binary_logloss: 0.223029\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction, val_score: 0.223029:  86%|######################################5      | 6/7 [00:04<00:00,  1.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction, val_score: 0.223029: 100%|#############################################| 7/7 [00:04<00:00,  1.77it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:23,335]\u001b[0m Trial 6 finished with value: 0.2244617901170969 and parameters: {'feature_fraction': 0.7}. Best is trial 5 with value: 0.2230286881679849.\u001b[0m\n",
      "feature_fraction, val_score: 0.223029: 100%|#############################################| 7/7 [00:04<00:00,  1.72it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:   0%|                                                          | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.117366\tvalid_1's binary_logloss: 0.232444\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.163098\tvalid_1's binary_logloss: 0.224462\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0357779\tvalid_1's binary_logloss: 0.265714\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's binary_logloss: 0.112819\tvalid_1's binary_logloss: 0.231543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:   0%|                                                          | 0/20 [00:01<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:   5%|##5                                               | 1/20 [00:01<00:19,  1.02s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:24,362]\u001b[0m Trial 7 finished with value: 0.23154255008640115 and parameters: {'num_leaves': 96}. Best is trial 7 with value: 0.23154255008640115.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:   5%|##5                                               | 1/20 [00:01<00:19,  1.02s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0193027\tvalid_1's binary_logloss: 0.292942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:   5%|##5                                               | 1/20 [00:02<00:19,  1.02s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  10%|#####                                             | 2/20 [00:02<00:20,  1.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:25,542]\u001b[0m Trial 8 finished with value: 0.23188340454656967 and parameters: {'num_leaves': 139}. Best is trial 7 with value: 0.23154255008640115.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  10%|#####                                             | 2/20 [00:02<00:20,  1.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's binary_logloss: 0.118108\tvalid_1's binary_logloss: 0.231883\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0227993\tvalid_1's binary_logloss: 0.286629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  10%|#####                                             | 2/20 [00:03<00:20,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  15%|#######5                                          | 3/20 [00:03<00:18,  1.11s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:26,656]\u001b[0m Trial 9 finished with value: 0.23424462561248463 and parameters: {'num_leaves': 126}. Best is trial 7 with value: 0.23154255008640115.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  15%|#######5                                          | 3/20 [00:03<00:18,  1.11s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.123542\tvalid_1's binary_logloss: 0.234245\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0129878\tvalid_1's binary_logloss: 0.310187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  15%|#######5                                          | 3/20 [00:05<00:18,  1.11s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  20%|##########                                        | 4/20 [00:05<00:22,  1.40s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:28,505]\u001b[0m Trial 10 finished with value: 0.23679171060420295 and parameters: {'num_leaves': 243}. Best is trial 7 with value: 0.23154255008640115.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  20%|##########                                        | 4/20 [00:05<00:22,  1.40s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's binary_logloss: 0.119694\tvalid_1's binary_logloss: 0.236792\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.2561\tvalid_1's binary_logloss: 0.255776\n",
      "[200]\tvalid_0's binary_logloss: 0.241807\tvalid_1's binary_logloss: 0.245962\n",
      "[300]\tvalid_0's binary_logloss: 0.235519\tvalid_1's binary_logloss: 0.243106\n",
      "[400]\tvalid_0's binary_logloss: 0.231524\tvalid_1's binary_logloss: 0.242298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  20%|##########                                        | 4/20 [00:05<00:22,  1.40s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  25%|############5                                     | 5/20 [00:05<00:16,  1.09s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:29,046]\u001b[0m Trial 11 finished with value: 0.24139576602760077 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.23154255008640115.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  25%|############5                                     | 5/20 [00:05<00:16,  1.09s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[500]\tvalid_0's binary_logloss: 0.228642\tvalid_1's binary_logloss: 0.241539\n",
      "[600]\tvalid_0's binary_logloss: 0.226085\tvalid_1's binary_logloss: 0.241915\n",
      "Early stopping, best iteration is:\n",
      "[503]\tvalid_0's binary_logloss: 0.228565\tvalid_1's binary_logloss: 0.241396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0137154\tvalid_1's binary_logloss: 0.302813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  25%|############5                                     | 5/20 [00:07<00:16,  1.09s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  30%|###############                                   | 6/20 [00:07<00:18,  1.31s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:30,793]\u001b[0m Trial 12 finished with value: 0.2355948799680185 and parameters: {'num_leaves': 256}. Best is trial 7 with value: 0.23154255008640115.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  30%|###############                                   | 6/20 [00:07<00:18,  1.31s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's binary_logloss: 0.112845\tvalid_1's binary_logloss: 0.235595\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.217675\tvalid_1's binary_logloss: 0.229786\n",
      "[200]\tvalid_0's binary_logloss: 0.201619\tvalid_1's binary_logloss: 0.227876\n",
      "[300]\tvalid_0's binary_logloss: 0.190219\tvalid_1's binary_logloss: 0.227546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  30%|###############                                   | 6/20 [00:07<00:18,  1.31s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  35%|#################5                                | 7/20 [00:07<00:13,  1.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:31,330]\u001b[0m Trial 13 finished with value: 0.22677735686157915 and parameters: {'num_leaves': 4}. Best is trial 13 with value: 0.22677735686157915.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  35%|#################5                                | 7/20 [00:07<00:13,  1.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's binary_logloss: 0.180301\tvalid_1's binary_logloss: 0.227522\n",
      "Early stopping, best iteration is:\n",
      "[378]\tvalid_0's binary_logloss: 0.182411\tvalid_1's binary_logloss: 0.226777\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0140691\tvalid_1's binary_logloss: 0.305264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  35%|#################5                                | 7/20 [00:09<00:13,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  40%|####################                              | 8/20 [00:09<00:14,  1.21s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:32,855]\u001b[0m Trial 14 finished with value: 0.23516614434119565 and parameters: {'num_leaves': 196}. Best is trial 13 with value: 0.22677735686157915.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  40%|####################                              | 8/20 [00:09<00:14,  1.21s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.124049\tvalid_1's binary_logloss: 0.235166\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  40%|####################                              | 8/20 [00:10<00:14,  1.21s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  45%|######################5                           | 9/20 [00:10<00:11,  1.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:33,579]\u001b[0m Trial 15 finished with value: 0.22807839599566088 and parameters: {'num_leaves': 56}. Best is trial 13 with value: 0.22677735686157915.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  45%|######################5                           | 9/20 [00:10<00:11,  1.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.0708208\tvalid_1's binary_logloss: 0.246923\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.138498\tvalid_1's binary_logloss: 0.228078\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0142546\tvalid_1's binary_logloss: 0.301413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  45%|######################5                           | 9/20 [00:11<00:11,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  50%|########################5                        | 10/20 [00:11<00:11,  1.19s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:35,075]\u001b[0m Trial 16 finished with value: 0.2341774149673067 and parameters: {'num_leaves': 193}. Best is trial 13 with value: 0.22677735686157915.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  50%|########################5                        | 10/20 [00:11<00:11,  1.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's binary_logloss: 0.127802\tvalid_1's binary_logloss: 0.234177\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  50%|########################5                        | 10/20 [00:12<00:11,  1.19s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  55%|##########################9                      | 11/20 [00:12<00:09,  1.05s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:35,789]\u001b[0m Trial 17 finished with value: 0.22740637152134505 and parameters: {'num_leaves': 53}. Best is trial 13 with value: 0.22677735686157915.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  55%|##########################9                      | 11/20 [00:12<00:09,  1.05s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.0748036\tvalid_1's binary_logloss: 0.246205\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.143088\tvalid_1's binary_logloss: 0.227406\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0135328\tvalid_1's binary_logloss: 0.300026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  55%|##########################9                      | 11/20 [00:14<00:09,  1.05s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  60%|#############################4                   | 12/20 [00:14<00:09,  1.20s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:37,349]\u001b[0m Trial 18 finished with value: 0.23335638935733943 and parameters: {'num_leaves': 209}. Best is trial 13 with value: 0.22677735686157915.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  60%|#############################4                   | 12/20 [00:14<00:09,  1.20s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.123387\tvalid_1's binary_logloss: 0.233356\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  60%|#############################4                   | 12/20 [00:14<00:09,  1.20s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  65%|###############################8                 | 13/20 [00:14<00:07,  1.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:38,082]\u001b[0m Trial 19 finished with value: 0.2262560867103443 and parameters: {'num_leaves': 45}. Best is trial 19 with value: 0.2262560867103443.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  65%|###############################8                 | 13/20 [00:14<00:07,  1.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.0857897\tvalid_1's binary_logloss: 0.241701\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's binary_logloss: 0.150278\tvalid_1's binary_logloss: 0.226256\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0164268\tvalid_1's binary_logloss: 0.294605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  65%|###############################8                 | 13/20 [00:16<00:07,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  70%|##################################3              | 14/20 [00:16<00:06,  1.13s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:39,377]\u001b[0m Trial 20 finished with value: 0.23339661897945593 and parameters: {'num_leaves': 158}. Best is trial 19 with value: 0.2262560867103443.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  70%|##################################3              | 14/20 [00:16<00:06,  1.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.124625\tvalid_1's binary_logloss: 0.233397\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  70%|##################################3              | 14/20 [00:16<00:06,  1.13s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.0424055\tvalid_1's binary_logloss: 0.265366\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's binary_logloss: 0.12937\tvalid_1's binary_logloss: 0.233999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  75%|####################################7            | 15/20 [00:16<00:05,  1.06s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:40,284]\u001b[0m Trial 21 finished with value: 0.23399908963057078 and parameters: {'num_leaves': 85}. Best is trial 19 with value: 0.2262560867103443.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  75%|####################################7            | 15/20 [00:16<00:05,  1.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.0139262\tvalid_1's binary_logloss: 0.300847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  75%|####################################7            | 15/20 [00:18<00:05,  1.06s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  80%|#######################################2         | 16/20 [00:18<00:04,  1.25s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:41,962]\u001b[0m Trial 22 finished with value: 0.23331866193561943 and parameters: {'num_leaves': 227}. Best is trial 19 with value: 0.2262560867103443.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  80%|#######################################2         | 16/20 [00:18<00:04,  1.25s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's binary_logloss: 0.123564\tvalid_1's binary_logloss: 0.233319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.131574\tvalid_1's binary_logloss: 0.228085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  80%|#######################################2         | 16/20 [00:19<00:04,  1.25s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.223029:  85%|#########################################6       | 17/20 [00:19<00:03,  1.03s/it]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:42,498]\u001b[0m Trial 23 finished with value: 0.22340210735088364 and parameters: {'num_leaves': 24}. Best is trial 23 with value: 0.22340210735088364.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.223029:  85%|#########################################6       | 17/20 [00:19<00:03,  1.03s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's binary_logloss: 0.178166\tvalid_1's binary_logloss: 0.223402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.137687\tvalid_1's binary_logloss: 0.227547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.222100:  85%|#########################################6       | 17/20 [00:19<00:03,  1.03s/it]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.222100:  90%|############################################1    | 18/20 [00:19<00:01,  1.14it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:43,022]\u001b[0m Trial 24 finished with value: 0.22209954436340462 and parameters: {'num_leaves': 22}. Best is trial 24 with value: 0.22209954436340462.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.222100:  90%|############################################1    | 18/20 [00:19<00:01,  1.14it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's binary_logloss: 0.181783\tvalid_1's binary_logloss: 0.2221\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.147069\tvalid_1's binary_logloss: 0.224738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.220951:  90%|############################################1    | 18/20 [00:20<00:01,  1.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.220951:  95%|##############################################5  | 19/20 [00:20<00:00,  1.29it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:43,558]\u001b[0m Trial 25 finished with value: 0.220951102222381 and parameters: {'num_leaves': 19}. Best is trial 25 with value: 0.220951102222381.\u001b[0m\n",
      "\n",
      "\n",
      "num_leaves, val_score: 0.220951:  95%|##############################################5  | 19/20 [00:20<00:00,  1.29it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.171872\tvalid_1's binary_logloss: 0.220951\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "num_leaves, val_score: 0.220951:  95%|##############################################5  | 19/20 [00:20<00:00,  1.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "num_leaves, val_score: 0.220951: 100%|#################################################| 20/20 [00:20<00:00,  1.41it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:44,106]\u001b[0m Trial 26 finished with value: 0.22275606268849768 and parameters: {'num_leaves': 28}. Best is trial 25 with value: 0.220951102222381.\u001b[0m\n",
      "num_leaves, val_score: 0.220951: 100%|#################################################| 20/20 [00:20<00:00,  1.04s/it]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220951:   0%|                                                             | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.120106\tvalid_1's binary_logloss: 0.22809\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's binary_logloss: 0.170235\tvalid_1's binary_logloss: 0.222756\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220951:   0%|                                                             | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220951:  10%|#####3                                               | 1/10 [00:00<00:07,  1.28it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:44,898]\u001b[0m Trial 27 finished with value: 0.22572770556036378 and parameters: {'bagging_fraction': 0.624119183389415, 'bagging_freq': 2}. Best is trial 27 with value: 0.22572770556036378.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220951:  10%|#####3                                               | 1/10 [00:00<00:07,  1.28it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146905\tvalid_1's binary_logloss: 0.230817\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's binary_logloss: 0.176656\tvalid_1's binary_logloss: 0.225728\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220951:  10%|#####3                                               | 1/10 [00:01<00:07,  1.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220951:  20%|##########6                                          | 2/10 [00:01<00:05,  1.47it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:45,505]\u001b[0m Trial 28 finished with value: 0.2210787512885638 and parameters: {'bagging_fraction': 0.9720687950371548, 'bagging_freq': 7}. Best is trial 28 with value: 0.2210787512885638.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220951:  20%|##########6                                          | 2/10 [00:01<00:05,  1.47it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146562\tvalid_1's binary_logloss: 0.225196\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.176747\tvalid_1's binary_logloss: 0.221079\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220951:  20%|##########6                                          | 2/10 [00:01<00:05,  1.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220951:  30%|###############9                                     | 3/10 [00:01<00:04,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:46,106]\u001b[0m Trial 29 finished with value: 0.2219483747666601 and parameters: {'bagging_fraction': 0.9905876057792903, 'bagging_freq': 7}. Best is trial 28 with value: 0.2210787512885638.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220951:  30%|###############9                                     | 3/10 [00:01<00:04,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.14704\tvalid_1's binary_logloss: 0.223664\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's binary_logloss: 0.17953\tvalid_1's binary_logloss: 0.221948\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220935:  30%|###############9                                     | 3/10 [00:02<00:04,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220935:  40%|#####################2                               | 4/10 [00:02<00:03,  1.59it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:46,708]\u001b[0m Trial 30 finished with value: 0.2209350252324085 and parameters: {'bagging_fraction': 0.9944094400808202, 'bagging_freq': 7}. Best is trial 30 with value: 0.2209350252324085.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220935:  40%|#####################2                               | 4/10 [00:02<00:03,  1.59it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146986\tvalid_1's binary_logloss: 0.224205\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.176494\tvalid_1's binary_logloss: 0.220935\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220935:  40%|#####################2                               | 4/10 [00:03<00:03,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220935:  50%|##########################5                          | 5/10 [00:03<00:03,  1.61it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:47,317]\u001b[0m Trial 31 finished with value: 0.22124612957953393 and parameters: {'bagging_fraction': 0.9759962420548092, 'bagging_freq': 7}. Best is trial 30 with value: 0.2209350252324085.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220935:  50%|##########################5                          | 5/10 [00:03<00:03,  1.61it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146231\tvalid_1's binary_logloss: 0.22588\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.176875\tvalid_1's binary_logloss: 0.221246\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220935:  50%|##########################5                          | 5/10 [00:03<00:03,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220935:  60%|###############################8                     | 6/10 [00:03<00:02,  1.61it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:47,945]\u001b[0m Trial 32 finished with value: 0.22268415884600862 and parameters: {'bagging_fraction': 0.9427241440039437, 'bagging_freq': 7}. Best is trial 30 with value: 0.2209350252324085.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220935:  60%|###############################8                     | 6/10 [00:03<00:02,  1.61it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.145936\tvalid_1's binary_logloss: 0.225987\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.177479\tvalid_1's binary_logloss: 0.222684\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's binary_logloss: 0.147361\tvalid_1's binary_logloss: 0.224081\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's binary_logloss: 0.162361\tvalid_1's binary_logloss: 0.220857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  60%|###############################8                     | 6/10 [00:04<00:02,  1.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220857:  70%|#####################################                | 7/10 [00:04<00:01,  1.54it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:48,647]\u001b[0m Trial 33 finished with value: 0.2208570103493476 and parameters: {'bagging_fraction': 0.9913490101029431, 'bagging_freq': 7}. Best is trial 33 with value: 0.2208570103493476.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  70%|#####################################                | 7/10 [00:04<00:01,  1.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  70%|#####################################                | 7/10 [00:05<00:01,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220857:  80%|##########################################4          | 8/10 [00:05<00:01,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:49,316]\u001b[0m Trial 34 finished with value: 0.22322979584444116 and parameters: {'bagging_fraction': 0.8586973274255432, 'bagging_freq': 5}. Best is trial 33 with value: 0.2208570103493476.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  80%|##########################################4          | 8/10 [00:05<00:01,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146451\tvalid_1's binary_logloss: 0.227877\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's binary_logloss: 0.184141\tvalid_1's binary_logloss: 0.22323\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  80%|##########################################4          | 8/10 [00:05<00:01,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220857:  90%|###############################################7     | 9/10 [00:05<00:00,  1.59it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:49,885]\u001b[0m Trial 35 finished with value: 0.23488076679052738 and parameters: {'bagging_fraction': 0.4232573385165163, 'bagging_freq': 6}. Best is trial 33 with value: 0.2208570103493476.\u001b[0m\n",
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  90%|###############################################7     | 9/10 [00:05<00:00,  1.59it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.154973\tvalid_1's binary_logloss: 0.245144\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's binary_logloss: 0.191727\tvalid_1's binary_logloss: 0.234881\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "bagging, val_score: 0.220857:  90%|###############################################7     | 9/10 [00:06<00:00,  1.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "bagging, val_score: 0.220857: 100%|####################################################| 10/10 [00:06<00:00,  1.59it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:50,510]\u001b[0m Trial 36 finished with value: 0.22518531910757306 and parameters: {'bagging_fraction': 0.8363677099807942, 'bagging_freq': 7}. Best is trial 33 with value: 0.2208570103493476.\u001b[0m\n",
      "bagging, val_score: 0.220857: 100%|####################################################| 10/10 [00:06<00:00,  1.56it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:   0%|                                              | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.145958\tvalid_1's binary_logloss: 0.230534\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's binary_logloss: 0.177561\tvalid_1's binary_logloss: 0.225185\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:   0%|                                              | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  17%|######3                               | 1/6 [00:00<00:03,  1.63it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:51,133]\u001b[0m Trial 37 finished with value: 0.22279470817985655 and parameters: {'feature_fraction': 0.9159999999999999}. Best is trial 37 with value: 0.22279470817985655.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  17%|######3                               | 1/6 [00:00<00:03,  1.63it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147274\tvalid_1's binary_logloss: 0.227038\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.182084\tvalid_1's binary_logloss: 0.222795\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  17%|######3                               | 1/6 [00:01<00:03,  1.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  33%|############6                         | 2/6 [00:01<00:02,  1.58it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:51,783]\u001b[0m Trial 38 finished with value: 0.22152028759582285 and parameters: {'feature_fraction': 0.948}. Best is trial 38 with value: 0.22152028759582285.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  33%|############6                         | 2/6 [00:01<00:02,  1.58it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146094\tvalid_1's binary_logloss: 0.223589\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's binary_logloss: 0.169216\tvalid_1's binary_logloss: 0.22152\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  33%|############6                         | 2/6 [00:01<00:02,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  50%|###################                   | 3/6 [00:01<00:01,  1.62it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:52,378]\u001b[0m Trial 39 finished with value: 0.22100142543016577 and parameters: {'feature_fraction': 0.9799999999999999}. Best is trial 39 with value: 0.22100142543016577.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220857:  50%|###################                   | 3/6 [00:01<00:01,  1.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146226\tvalid_1's binary_logloss: 0.226347\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's binary_logloss: 0.183116\tvalid_1's binary_logloss: 0.221001\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311:  50%|###################                   | 3/6 [00:02<00:01,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311:  67%|#########################3            | 4/6 [00:02<00:01,  1.60it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:53,011]\u001b[0m Trial 40 finished with value: 0.22031140148098 and parameters: {'feature_fraction': 0.852}. Best is trial 40 with value: 0.22031140148098.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311:  67%|#########################3            | 4/6 [00:02<00:01,  1.60it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146711\tvalid_1's binary_logloss: 0.221205\n",
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's binary_logloss: 0.155027\tvalid_1's binary_logloss: 0.220476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.220311:  67%|#########################3            | 4/6 [00:03<00:01,  1.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311:  83%|###############################6      | 5/6 [00:03<00:00,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:53,677]\u001b[0m Trial 41 finished with value: 0.2204761522121526 and parameters: {'feature_fraction': 0.82}. Best is trial 40 with value: 0.22031140148098.\u001b[0m\n",
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311:  83%|###############################6      | 5/6 [00:03<00:00,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311:  83%|###############################6      | 5/6 [00:03<00:00,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "feature_fraction_stage2, val_score: 0.220311: 100%|######################################| 6/6 [00:03<00:00,  1.56it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:54,318]\u001b[0m Trial 42 finished with value: 0.2226667111802563 and parameters: {'feature_fraction': 0.8839999999999999}. Best is trial 40 with value: 0.22031140148098.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.220311: 100%|######################################| 6/6 [00:03<00:00,  1.58it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220311:   0%|                                              | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.146781\tvalid_1's binary_logloss: 0.226643\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's binary_logloss: 0.178103\tvalid_1's binary_logloss: 0.222667\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220311:   0%|                                              | 0/20 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220311:   5%|#9                                    | 1/20 [00:00<00:12,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:54,981]\u001b[0m Trial 43 finished with value: 0.2223619729756422 and parameters: {'lambda_l1': 8.96226493498497e-06, 'lambda_l2': 0.058289129226504824}. Best is trial 43 with value: 0.2223619729756422.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220311:   5%|#9                                    | 1/20 [00:00<00:12,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.148271\tvalid_1's binary_logloss: 0.225829\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.174146\tvalid_1's binary_logloss: 0.222362\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:   5%|#9                                    | 1/20 [00:01<00:12,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  10%|###8                                  | 2/20 [00:01<00:11,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:55,618]\u001b[0m Trial 44 finished with value: 0.22006881931676917 and parameters: {'lambda_l1': 1.666539574628305, 'lambda_l2': 1.6574680675678002e-07}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  10%|###8                                  | 2/20 [00:01<00:11,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.162989\tvalid_1's binary_logloss: 0.222151\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's binary_logloss: 0.183363\tvalid_1's binary_logloss: 0.220069\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  10%|###8                                  | 2/20 [00:01<00:11,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  15%|#####7                                | 3/20 [00:01<00:10,  1.67it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:56,164]\u001b[0m Trial 45 finished with value: 0.22273937826680237 and parameters: {'lambda_l1': 8.609522540548587, 'lambda_l2': 4.054246709307919e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  15%|#####7                                | 3/20 [00:01<00:10,  1.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.196654\tvalid_1's binary_logloss: 0.222985\n",
      "[200]\tvalid_0's binary_logloss: 0.195767\tvalid_1's binary_logloss: 0.222753\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's binary_logloss: 0.195793\tvalid_1's binary_logloss: 0.222739\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  15%|#####7                                | 3/20 [00:02<00:10,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  20%|#######6                              | 4/20 [00:02<00:09,  1.67it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:56,763]\u001b[0m Trial 46 finished with value: 0.22243278613691891 and parameters: {'lambda_l1': 8.402432098799672, 'lambda_l2': 5.243606603759894e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  20%|#######6                              | 4/20 [00:02<00:09,  1.67it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.195163\tvalid_1's binary_logloss: 0.222499\n",
      "[200]\tvalid_0's binary_logloss: 0.193231\tvalid_1's binary_logloss: 0.222433\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's binary_logloss: 0.193231\tvalid_1's binary_logloss: 0.222433\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  20%|#######6                              | 4/20 [00:03<00:09,  1.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  25%|#########5                            | 5/20 [00:03<00:09,  1.64it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:57,390]\u001b[0m Trial 47 finished with value: 0.22158721932601902 and parameters: {'lambda_l1': 0.030547663911973073, 'lambda_l2': 2.4545562393102397e-05}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  25%|#########5                            | 5/20 [00:03<00:09,  1.64it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.148157\tvalid_1's binary_logloss: 0.22414\n",
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's binary_logloss: 0.174222\tvalid_1's binary_logloss: 0.221587\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  25%|#########5                            | 5/20 [00:03<00:09,  1.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  30%|###########4                          | 6/20 [00:03<00:08,  1.62it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:58,019]\u001b[0m Trial 48 finished with value: 0.22142940188867197 and parameters: {'lambda_l1': 0.00444001245147785, 'lambda_l2': 3.385572288432495e-05}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  30%|###########4                          | 6/20 [00:03<00:08,  1.62it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.148288\tvalid_1's binary_logloss: 0.225149\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's binary_logloss: 0.183219\tvalid_1's binary_logloss: 0.221429\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  30%|###########4                          | 6/20 [00:04<00:08,  1.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  35%|#############3                        | 7/20 [00:04<00:08,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:58,696]\u001b[0m Trial 49 finished with value: 0.2203114015336305 and parameters: {'lambda_l1': 2.8892670038876983e-08, 'lambda_l2': 1.3798151537525522e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  35%|#############3                        | 7/20 [00:04<00:08,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  35%|#############3                        | 7/20 [00:05<00:08,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  40%|###############2                      | 8/20 [00:05<00:07,  1.54it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:26:59,374]\u001b[0m Trial 50 finished with value: 0.2203114015533211 and parameters: {'lambda_l1': 3.201394226898577e-08, 'lambda_l2': 2.3498826488198717e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  40%|###############2                      | 8/20 [00:05<00:07,  1.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  40%|###############2                      | 8/20 [00:05<00:07,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  45%|#################1                    | 9/20 [00:05<00:07,  1.50it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:00,077]\u001b[0m Trial 51 finished with value: 0.22031140151259263 and parameters: {'lambda_l1': 1.1206967043046277e-08, 'lambda_l2': 1.2721850477833899e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  45%|#################1                    | 9/20 [00:05<00:07,  1.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  45%|#################1                    | 9/20 [00:06<00:07,  1.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  50%|##################5                  | 10/20 [00:06<00:06,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:00,737]\u001b[0m Trial 52 finished with value: 0.22031140153710915 and parameters: {'lambda_l1': 2.1239697391505295e-08, 'lambda_l2': 1.9277315573546594e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  50%|##################5                  | 10/20 [00:06<00:06,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  50%|##################5                  | 10/20 [00:07<00:06,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  55%|####################3                | 11/20 [00:07<00:05,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:01,390]\u001b[0m Trial 53 finished with value: 0.22031140153206022 and parameters: {'lambda_l1': 2.0627189527597487e-08, 'lambda_l2': 1.7078611919304365e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  55%|####################3                | 11/20 [00:07<00:05,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  55%|####################3                | 11/20 [00:07<00:05,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  60%|######################2              | 12/20 [00:07<00:05,  1.54it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:02,018]\u001b[0m Trial 54 finished with value: 0.2203114015377306 and parameters: {'lambda_l1': 1.3154202495389515e-08, 'lambda_l2': 2.035294866670826e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  60%|######################2              | 12/20 [00:07<00:05,  1.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  60%|######################2              | 12/20 [00:08<00:05,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  65%|########################             | 13/20 [00:08<00:04,  1.54it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:02,667]\u001b[0m Trial 55 finished with value: 0.22031140151456738 and parameters: {'lambda_l1': 1.2179722369942516e-08, 'lambda_l2': 1.358403775725523e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  65%|########################             | 13/20 [00:08<00:04,  1.54it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  65%|########################             | 13/20 [00:08<00:04,  1.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  70%|#########################9           | 14/20 [00:08<00:03,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:03,305]\u001b[0m Trial 56 finished with value: 0.22031140180988423 and parameters: {'lambda_l1': 5.458263631932523e-07, 'lambda_l2': 1.0074795713238318e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  70%|#########################9           | 14/20 [00:08<00:03,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  70%|#########################9           | 14/20 [00:09<00:03,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  75%|###########################7         | 15/20 [00:09<00:03,  1.56it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:03,930]\u001b[0m Trial 57 finished with value: 0.22031140337640875 and parameters: {'lambda_l1': 1.2257305149627012e-08, 'lambda_l2': 7.545246270343941e-07}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  75%|###########################7         | 15/20 [00:09<00:03,  1.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  75%|###########################7         | 15/20 [00:10<00:03,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  80%|#############################6       | 16/20 [00:10<00:02,  1.58it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:04,551]\u001b[0m Trial 58 finished with value: 0.22031140340553182 and parameters: {'lambda_l1': 3.849423995198905e-07, 'lambda_l2': 6.910215480191122e-07}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  80%|#############################6       | 16/20 [00:10<00:02,  1.58it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  80%|#############################6       | 16/20 [00:10<00:02,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  85%|###############################4     | 17/20 [00:10<00:01,  1.56it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:05,205]\u001b[0m Trial 59 finished with value: 0.2203114027299699 and parameters: {'lambda_l1': 2.2450214582584493e-07, 'lambda_l2': 4.5034615587716136e-07}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  85%|###############################4     | 17/20 [00:10<00:01,  1.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  85%|###############################4     | 17/20 [00:11<00:01,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  90%|#################################3   | 18/20 [00:11<00:01,  1.56it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:05,850]\u001b[0m Trial 60 finished with value: 0.22031140150965342 and parameters: {'lambda_l1': 1.6041691731617505e-08, 'lambda_l2': 1.0898158070366933e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  90%|#################################3   | 18/20 [00:11<00:01,  1.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  90%|#################################3   | 18/20 [00:12<00:01,  1.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  95%|###################################1 | 19/20 [00:12<00:00,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:06,475]\u001b[0m Trial 61 finished with value: 0.22031140151201356 and parameters: {'lambda_l1': 1.5870725302197872e-08, 'lambda_l2': 1.2342407947408062e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  95%|###################################1 | 19/20 [00:12<00:00,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "regularization_factors, val_score: 0.220069:  95%|###################################1 | 19/20 [00:12<00:00,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "regularization_factors, val_score: 0.220069: 100%|#####################################| 20/20 [00:12<00:00,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:07,115]\u001b[0m Trial 62 finished with value: 0.22031140150597375 and parameters: {'lambda_l1': 1.0174372138069568e-08, 'lambda_l2': 1.0043796348143832e-08}. Best is trial 44 with value: 0.22006881931676917.\u001b[0m\n",
      "regularization_factors, val_score: 0.220069: 100%|#####################################| 20/20 [00:12<00:00,  1.56it/s]\n",
      "\n",
      "\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:   0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.147177\tvalid_1's binary_logloss: 0.223092\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.172419\tvalid_1's binary_logloss: 0.220311\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:   0%|                                                     | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  20%|#########                                    | 1/5 [00:00<00:02,  1.51it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:07,785]\u001b[0m Trial 63 finished with value: 0.2235084476413932 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.2235084476413932.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  20%|#########                                    | 1/5 [00:00<00:02,  1.51it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.16666\tvalid_1's binary_logloss: 0.226038\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's binary_logloss: 0.182792\tvalid_1's binary_logloss: 0.223508\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  20%|#########                                    | 1/5 [00:01<00:02,  1.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  40%|##################                           | 2/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:08,404]\u001b[0m Trial 64 finished with value: 0.22048597839656076 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.22048597839656076.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  40%|##################                           | 2/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.161924\tvalid_1's binary_logloss: 0.223144\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.178757\tvalid_1's binary_logloss: 0.220486\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  40%|##################                           | 2/5 [00:01<00:01,  1.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  60%|###########################                  | 3/5 [00:01<00:01,  1.55it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:09,056]\u001b[0m Trial 65 finished with value: 0.22431161230299582 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.22048597839656076.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  60%|###########################                  | 3/5 [00:01<00:01,  1.55it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.171874\tvalid_1's binary_logloss: 0.225488\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's binary_logloss: 0.189281\tvalid_1's binary_logloss: 0.224312\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.162506\tvalid_1's binary_logloss: 0.223002\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's binary_logloss: 0.171598\tvalid_1's binary_logloss: 0.220563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.220069:  60%|###########################                  | 3/5 [00:02<00:01,  1.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  80%|####################################         | 4/5 [00:02<00:00,  1.53it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:09,726]\u001b[0m Trial 66 finished with value: 0.22056319937486532 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.22048597839656076.\u001b[0m\n",
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.220069:  80%|####################################         | 4/5 [00:02<00:00,  1.53it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "min_data_in_leaf, val_score: 0.219180:  80%|####################################         | 4/5 [00:03<00:00,  1.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "min_data_in_leaf, val_score: 0.219180: 100%|#############################################| 5/5 [00:03<00:00,  1.57it/s]\u001b[A\u001b[A\u001b[32m[I 2021-01-04 22:27:10,335]\u001b[0m Trial 67 finished with value: 0.21918032287290917 and parameters: {'min_child_samples': 10}. Best is trial 67 with value: 0.21918032287290917.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.219180: 100%|#############################################| 5/5 [00:03<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's binary_logloss: 0.161345\tvalid_1's binary_logloss: 0.221186\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's binary_logloss: 0.180677\tvalid_1's binary_logloss: 0.21918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna.integration.lightgbm as olgb\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data_1, labels, test_size=0.3, random_state=42)\n",
    "train_label = np.asarray(y_train)\n",
    "val_label = np.asarray(y_test)\n",
    "data = np.asarray(X_train)\n",
    "val = np.asarray(X_test)\n",
    "train_data = olgb.Dataset(data=data, label = train_label)\n",
    "test_data = olgb.Dataset(data=val, label=val_label)\n",
    "clf = olgb.train(params,\n",
    "        train_data,\n",
    "        valid_sets=[train_data, test_data],\n",
    "        verbose_eval=100,\n",
    "        early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': {'auc', 'binary_logloss'},\n",
       " 'verbosity': -1,\n",
       " 'boosting_type': 'gbdt',\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 1.666539574628305,\n",
       " 'lambda_l2': 1.6574680675678002e-07,\n",
       " 'num_leaves': 19,\n",
       " 'feature_fraction': 0.852,\n",
       " 'bagging_fraction': 0.9913490101029431,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 10,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 100}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = clf.params\n",
    "params['metric'] = {'binary_logloss', 'auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\lightgbm\\engine.py:151: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "D:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\lightgbm\\engine.py:156: UserWarning: Found `early_stopping_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.97639\ttraining's binary_logloss: 0.161345\tvalid_1's auc: 0.945294\tvalid_1's binary_logloss: 0.221186\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's auc: 0.961779\ttraining's binary_logloss: 0.199472\tvalid_1's auc: 0.946506\tvalid_1's binary_logloss: 0.22268\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Int64Index([    0,     3,     6,     7,     8,     9,    10,    11,    12,\\n               13,\\n            ...\\n            10568, 10569, 10570, 10571, 10572, 10573, 10574, 10575, 10576,\\n            10577],\\n           dtype='int64', length=8462)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-4e43a4759f85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfold_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fold {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfold_\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtrn_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrn_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2910\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2912\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1254\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\envs\\fcz_project\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1296\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1298\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Int64Index([    0,     3,     6,     7,     8,     9,    10,    11,    12,\\n               13,\\n            ...\\n            10568, 10569, 10570, 10571, 10572, 10573, 10574, 10575, 10576,\\n            10577],\\n           dtype='int64', length=8462)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2019)\n",
    "prob_oof = np.zeros((train_data_1.shape[0], ))\n",
    "test_pred_prob = np.zeros((test_data_1.shape[0], ))\n",
    "labels = label\n",
    "feature_importance_df = pd.DataFrame()\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_data_1)):\n",
    "    print(\"fold {}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(train_data_1.iloc[trn_idx], label=labels[trn_idx])\n",
    "    val_data = lgb.Dataset(train_data_1.iloc[val_idx], label=labels[val_idx])\n",
    "\n",
    "\n",
    "    clf = lgb.train(params,\n",
    "                    trn_data,\n",
    "                    valid_sets=[trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds=100)\n",
    "    prob_oof[val_idx] = clf.predict(train_data_1.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = list(train_data_1.columns)\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    test_pred_prob += clf.predict(test_data_1, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
